{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f105b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv', encoding='utf-8')\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the trans time into categorical data (Night, day, etc)\n",
    "# timestamp and hour are helper cols only\n",
    "df['timestamp'] = pd.to_datetime(df['Transaction_Time'], format='%H:%M:%S')\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "def categorize_time(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Noon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df['time_period'] = df['hour'].apply(categorize_time)\n",
    "\n",
    "# Convert to numerical for your model\n",
    "df = pd.get_dummies(df, columns=['time_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(\n",
    "    columns=[\n",
    "        # 'Customer_ID', \n",
    "        'Customer_Name', \n",
    "        'Transaction_ID', \n",
    "        'Merchant_ID', \n",
    "        'Customer_Contact', \n",
    "        'Customer_Email', \n",
    "        'Transaction_Description',\n",
    "        'Transaction_Date', \n",
    "        'Transaction_Time',\n",
    "        'Bank_Name',\n",
    "        'City',\n",
    "        'Gender'\n",
    "    ],\n",
    "    errors='ignore' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bankrupt_ratio(df):\n",
    "    # add 0.01 to avoid dividing to 0\n",
    "    df['amount_to_balance_ratio'] = df['Transaction_Amount'] / (df['Account_Balance'] + 0.01)\n",
    "    return df\n",
    "\n",
    "def high_amount_night(df):\n",
    "    is_night = (df['time_period_Night'] == True)\n",
    "    \n",
    "    # 2. Define \"High Amount\" (e.g., Top 10% of all transactions)\n",
    "    # We calculate the 90th percentile dynamically\n",
    "    high_threshold = df['Transaction_Amount'].quantile(0.90)\n",
    "    is_high_amount = df['Transaction_Amount'] > high_threshold\n",
    "\n",
    "    # 3. Combine: If BOTH are True, return 1. Else 0.\n",
    "    df['high_amount_night'] = (is_night & is_high_amount).astype(int)\n",
    "    return df\n",
    "\n",
    "def velocity_check(df):\n",
    "    # 1. Ensure timestamp is datetime (just in case)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # 2. Sort is MANDATORY for rolling time windows\n",
    "    df = df.sort_values(['Customer_ID', 'timestamp'])\n",
    "\n",
    "    # 3. Calculate Velocity using an index-based approach\n",
    "    # We set the index to timestamp so rolling('24h') knows what to measure\n",
    "    df['velocity_24h'] = (\n",
    "        df.set_index('timestamp')\n",
    "          .groupby('Customer_ID')\n",
    "          ['Transaction_Amount'] # We can count any column\n",
    "          .rolling('24h')\n",
    "          .count()\n",
    "          .reset_index(level=0, drop=True) # Remove the Customer_ID index level\n",
    "          .values # Extract the raw numbers to put back in the original df\n",
    "    )\n",
    "    \n",
    "    df['velocity_6h'] = (\n",
    "        df.set_index('timestamp')\n",
    "          .groupby('Customer_ID')\n",
    "          ['Transaction_Amount']\n",
    "          .rolling('6h')\n",
    "          .count()\n",
    "          .reset_index(level=0, drop=True)\n",
    "          .values\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def savings_attack(df):\n",
    "    # Logic: Is it a Savings account AND has a high 6h velocity?\n",
    "    # We use 2 as the threshold as per your project plan\n",
    "    df['is_savings_attack'] = (\n",
    "        (df['Account_Type'] == 'Savings') & \n",
    "        (df['velocity_6h'] >= 2)\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def is_outlier(df):\n",
    "    # 1. Calculate mean and std for each customer\n",
    "    # transform('std') returns NaN for customers with only 1 transaction\n",
    "    customer_mean = df.groupby(\"Customer_ID\")[\"Transaction_Amount\"].transform(\"mean\")\n",
    "    customer_std = df.groupby(\"Customer_ID\")[\"Transaction_Amount\"].transform(\"std\")\n",
    "    \n",
    "    # 2. FIX: Replace NaN standard deviation with 0\n",
    "    # This happens for any customer who has only 1 transaction in the data\n",
    "    customer_std = customer_std.fillna(0)\n",
    "    \n",
    "    # 3. Calculate the Z-score\n",
    "    # Adding 0.001 (epsilon) prevents the code from crashing when std is 0\n",
    "    df[\"user_z_score\"] = (df[\"Transaction_Amount\"] - customer_mean) / (customer_std + 0.001)\n",
    "    \n",
    "    df[\"is_outlier\"] = (df[\"user_z_score\"] > 1.5).astype(int)  \n",
    "    return df\n",
    "\n",
    "\n",
    "df_clean = bankrupt_ratio(df_clean)\n",
    "df_clean = high_amount_night(df_clean)\n",
    "df_clean = velocity_check(df_clean)\n",
    "df_clean = savings_attack(df_clean)\n",
    "df_clean = is_outlier(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0906198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final clean\n",
    "df_clean = df_clean.drop(\n",
    "    columns=[\n",
    "        'Customer_ID',\n",
    "        'timestamp'\n",
    "    ], \n",
    "    errors=\"ignore\"\n",
    ")\n",
    "\n",
    "# MOVE 'Is_Fraud' TO THE END\n",
    "# Create a list of all columns except 'Is_Fraud'\n",
    "cols = [col for col in df_clean.columns if col != 'Is_Fraud']\n",
    "\n",
    "# Append 'Is_Fraud' to the end of that list\n",
    "cols.append('Is_Fraud')\n",
    "\n",
    "# Reorder the dataframe\n",
    "df_clean = df_clean[cols]\n",
    "\n",
    "df_clean.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['Transaction_Amount', 'Account_Balance', 'amount_to_balance_ratio', 'velocity_6h', 'velocity_24h', 'is_savings_attack', 'is_outlier', 'Is_Fraud']\n",
    "\n",
    "df_clean = df_clean[keep_cols]\n",
    "\n",
    "df_clean.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['is_outlier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ecb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the Features and the Target\n",
    "X = df_clean.iloc[:, 0:-1]\n",
    "y = df_clean.iloc[:, -1]    # The isFraud col\n",
    "\n",
    "# Now split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=36)\n",
    "\n",
    "smote = SMOTE(k_neighbors=3)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled = X_resampled.round().astype(int)   # To avoid synthetic value being float like 1.5\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,          # Increase number of trees\n",
    "    class_weight={0: 1, 1: 25}, # Manually set higher weight for Fraud\n",
    "    max_depth=None,            # Let the trees grow deeper to find complex rules\n",
    "    min_samples_leaf=2,        # More specific rules\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf.fit(X_resampled, y_resampled)    # Training part\n",
    "joblib.dump(rf, \"rfFeaturePruning.joblib\") # Save for later use - when test on actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "score = rf.score(X_test, y_test)  \n",
    "print(score)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d527653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get feature importances from your trained model\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# 2. Create a DataFrame for easy plotting\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 3. Plot only the Top 15 (otherwise it gets too crowded)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(25), palette='viridis')\n",
    "\n",
    "plt.title('Top 15 Features for Detecting Fraud')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b64a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.head()\n",
    "df_clean[\"is_savings_attack\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
